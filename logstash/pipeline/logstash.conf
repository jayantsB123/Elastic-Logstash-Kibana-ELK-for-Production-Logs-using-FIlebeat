input {
  beats {
    port => 5044
  }
}

filter {
  ruby {
    init => "
    require 'yaml'
    config_file_path = '/etc/logstash/realm-patterns.yml'

    if File.exist?(config_file_path)
    @realm_config = YAML.load_file(config_file_path)
    else
    @realm_config = {
      'realm_patterns' => {},
      'field_patterns' => {},
      'application_mapping' => {}
    }
    warn('realm-patterns.yml not found at ' + config_file_path + '. Using empty configuration.')
    end
    "
    code => "
    if @realm_config['application_mapping'] && event.get('log_source')
    source = event.get('log_source')
    app_details = @realm_config['application_mapping'][source]
    if app_details
    app_details.each do |field, value|
    event.set('application_' + field, value)
    end
    end
    end
    if @realm_config['realm_patterns'] && event.get('realm')
    realm = event.get('realm')
    matched = false
    @realm_config['realm_patterns'].each do |category, details|
    details['patterns'].each do |pattern_str|
    if realm =~ /#{Regexp.escape(pattern_str)}/
    event.set('realm_category', category)
    event.set('event_type', details['event_type'])
    event.set('log_level', details['log_level'])
    matched = true
    break
    end
    end
    break if matched
    end

    if !matched
    event.set('realm_category', 'unknown')
    event.set('event_type', 'xml_unparsed')
    event.set('log_level', 'UNKNOWN')
    end
    end
    "
  }

  if [message] =~ /^<log/ {
    grok {
      match => { "message" => '<log realm="%{DATA:realm}" at="%{DATA:event_timestamp}"(?: lifespan="%{INT:lifespan_ms}ms")?.*?>\s*<(?<xml_message_type>info|warn|error|debug|trace|connect|commit)>' }
      tag_on_failure => ["_xml_wrapper_parse_failure"]
    }
    if [lifespan_ms] {
      mutate { convert => { "lifespan_ms" => "integer" } }
    }
    mutate { add_tag => ["xml_parsed"] }

    if [xml_message_type] == "info" {
      if [realm_category] == "api" {
        grok {
          match => { "message" => '(?m)<info>\s*<reqName>%{DATA:req_name}</reqName>\s*<txn>%{DATA:txn_id}</txn>\s*(?:<api\.source>%{DATA:api_source}</api\.source>\s*<source>%{GREEDYDATA:client_source_json}</source>\s*){1,2}.*?<clazz>%{DATA:dto_class}</clazz>' }
          tag_on_failure => ["_grok_api_info_parse_failure"]
        }
        if [client_source_json] {
          json {
            source => "client_source_json"
            target => "client_source"
            skip_on_invalid_json => true
          }
          mutate { remove_field => ["client_source_json"] }
        }
        grok {
          match => { "message" => '<institute>%{GREEDYDATA:institute_json}</institute>' }
          tag_on_failure => []
        }
        if [institute_json] {
          json {
            source => "institute_json"
            target => "institute"
            skip_on_invalid_json => true
          }
          mutate { remove_field => ["institute_json"] }
        }
      }
      else if [realm_category] == "job_scheduler" {
        grok {
          match => { "message" => '(?m)<info>\s*%{GREEDYDATA:job_info_message}' }
        }
        kv {
          source => "job_info_message"
          field_split => "\n"
          value_split => ":"
        }
        mutate {
          remove_field => ["job_info_message"]
        }
      }
      else {
        mutate { add_tag => ["_unhandled_info_message"] }
      }
    }
    else if [xml_message_type] == "warn" {
      grok {
        match => { "message" => '(?m)<warn>\s*%{GREEDYDATA:warning_message}' }
        tag_on_failure => ["_grok_warn_parse_failure"]
      }
      grok {
        match => { "warning_message" => 'Connection refused \(%{GREEDYDATA:refused_reason}\) \(%{IP:destination_ip}:%{INT:destination_port}\)' }
        tag_on_failure => ["_grok_connection_refused_parse_failure"]
      }
    }
    else if [xml_message_type] == "connect" {
      grok {
        match => { "message" => '(?m)<connect>\s*%{GREEDYDATA:connect_message}\s*</connect>' }
        tag_on_failure => ["_grok_connect_parse_failure"]
      }
      grok {
        match => { "connect_message" => 'Try %{INT:try_count} %{HOSTPORT:destination_host_and_port}.*?Unable to connect' }
      }
      mutate {
        split => { "destination_host_and_port" => ":" }
        add_field => { "destination_host" => "%{[destination_host_and_port][0]}" }
        add_field => { "destination_port" => "%{[destination_host_and_port][1]}" }
      }
      mutate { convert => { "destination_port" => "integer" } }
      mutate { remove_field => ["destination_host_and_port", "connect_message", "message"] }
    }
    else if [xml_message_type] == "commit" {
      grok {
        match => { "message" => '(?m)o.j.q.Constants.PATHPARAMS: {api=%{DATA:api}, txn=%{DATA:txn_id}}' }
        tag_on_failure => ["_grok_txn_id_parse_failure"]
      }
      grok {
        match => { "message" => '(?m)txnmgr-%{INT:txn_mgr_id}:%{GREEDYDATA:txn_mgr_details}\s*<context>(?<context_block>.*)</context>.*?<profiler>(?<profiler_block>.*)</profiler>' }
        tag_on_failure => ["_grok_commit_master_parse_failure"]
      }
      if [context_block] {
        grok {
          match => { "context_block" => "%{DATA:context_preamble}TXNNAME: %{DATA:transaction_name}.*?POJO: org.npci.pso.schema.%{DATA:pojo_class}.*?LOGEVT: (?<log_evt_block>.*)(?:SMS_RESPONSE: (?<sms_response_block>.*))?.*?(?:HTTP_RESPONSE: <![CDATA[(?<http_response_xml>.*)]]>)?%{DATA:context_postamble}" }
          tag_on_failure => ["_grok_commit_context_failure"]
        }
        if [log_evt_block] {
          kv {
            source => "log_evt_block"
            field_split => "\n"
            value_split => ":"
          }
          mutate { remove_field => ["log_evt_block"] }
        }
        if [http_response_xml] {
          xml {
            source => "http_response_xml"
            target => "http_response"
            store_xml => false
          }
          mutate { remove_field => ["http_response_xml"] }
        }

        mutate { remove_field => ["context_preamble", "context_postamble"] }
      }
      if [profiler_block] {
        kv {
          source => "profiler_block"
          field_split => ",\\s*"
          value_split => ":"
        }
        mutate { remove_field => ["profiler_block"] }
      }
    }
    else {
      mutate { add_tag => ["_unhandled_xml_message"] }
    }
  }
  else {
    mutate {
      add_tag => ["_unparsed_log"]
    }
  }

  # Parse timestamp
  if [event_timestamp] {
    mutate { gsub => ["event_timestamp", "\\.\\d+", ""] }
    date {
      match => [ "event_timestamp", "ISO8601" ]
      target => "@timestamp"
      timezone => "Asia/Kolkata"
    }
  }

  # Clean up fields for production
  mutate {
    remove_field => [
      "agent.ephemeral_id",
      "agent.id",
      "host.mac",
      "host.ip",
      "host.architecture",
      "host.containerized",
      "warning_message"
    ]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "jpos-prod-logs1-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "changeme"
  }
}
