input {
  beats {
    port => 5044
  }
}

filter {
  ruby {
      init => "require 'yaml' ;@realm_config = YAML.load_file('/etc/logstash/realm-patterns.yml')"
      code => "
        if event.get('log_source')
          source = event.get('log_source')
          app_details = @realm_config['application_mapping'][source]
          if app_details
            app_details.each do |field, value|
              event.set('application_' + field, value)
          end
        end
      end

      if event.get('realm')
        realm = event.get('realm')
        matched = false
        @realm_config['realm_patterns'].each do |category, details|
          details['patterns'].each do |pattern_str|
            if realm =~ /#{Regexp.escape(pattern_str)}/
              event.set('realm_category', category)
              event.set('event_type', details['event_type'])
              event.set('log_level', details['log_level'])
              matched = true
              break
            end
          end
          break if matched
      end
      if !matched
        event.set('realm_category', 'unknown')
        event.set('event_type', 'xml_unparsed')
        event.set('log_level', 'UNKNOWN')
      end
    end
    "
  }

  if [message] =~ /^<log/ {
    grok {
      match => { "message" => '<log realm="%{DATA:realm}" at="%{DATA:event_timestamp}"(?: lifespan="%{INT:lifespan_ms}ms")?.*?>\s*<(?<xml_message_type>info|warn|error|debug|trace|connect)>' }
      tag_on_failure => ["_xml_wrapper_parse_failure"]
    }
    if [lifespan_ms] {
    mutate { convert => { "lifespan_ms" => "integer" } }
  }
  mutate { add_tag => ["xml_parsed"] }

  if [xml_message_type] == "info" and [realm_category] == "api" {
    grok {
      match => { "message" => '(?m)<info>\s*<reqName>%{DATA:req_name}</reqName>\s*<txn>%{DATA:txn_id}</txn>\s*(?:<api\.source>%{DATA:api_source}</api\.source>\s*<source>%{GREEDYDATA:client_source_json}</source>\s*){1,2}.*?<clazz>%{DATA:dto_class}</clazz>' }
      tag_on_failure => ["_grok_api_info_parse_failure"]
    }
    if [client_source_json] {
      json {
        source => "client_source_json"
        target => "client_source"
        skip_on_invalid_json => true
      }
      mutate { remove_field => ["client_source_json"] }
    }
    grok {
      match => { "message" => '<institute>%{GREEDYDATA:institute_json}</institute>' }
      tag_on_failure => []
    }
    if [institute_json] {
      json {
        source => "institute_json"
        target => "institute"
        skip_on_invalid_json => true
      }
      mutate { remove_field => ["institute_json"] }
    }
  }
  else if [xml_message_type] == "warn" {
    grok {
      match => { "message" => '(?m)<warn>\s*%{GREEDYDATA:warning_message}' }
      tag_on_failure => ["_grok_warn_parse_failure"]
    }
    grok {
      match => { "warning_message" => 'Connection refused \(%{GREEDYDATA:refused_reason}\) \(%{IP:destination_ip}:%{INT:destination_port}\)' }
      tag_on_failure => ["_grok_connection_refused_parse_failure"]
    }
  }
  else if [xml_message_type] == "connect" {
    grok {
        match => { "message" => '(?m)<connect>\s*%{GREEDYDATA:connect_message}\s*</connect>' }
        tag_on_failure => ["_grok_connect_parse_failure"]
    }
    grok {
        match => { "connect_message" => 'Try %{INT:try_count} %{HOSTPORT:destination_host_and_port}.*?Unable to connect' }
    }
    mutate {
      split => { "destination_host_and_port" => ":" }
      add_field => { "destination_host" => "%{[destination_host_and_port][0]}" }
      add_field => { "destination_port" => "%{[destination_host_and_port][1]}" }
    }
    mutate { convert => { "destination_port" => "integer" } }
    mutate { remove_field => ["destination_host_and_port"] }
  }
  else {
      mutate { add_tag => ["_unhandled_xml_message"] }
  }
  } else {
    mutate {
      add_tag => ["_unparsed_log"]
    }
  }

  if [event_timestamp] {
    mutate { gsub => ["event_timestamp", "\\.\\d+", ""] }
    date {
      match => [ "event_timestamp", "ISO8601" ]
      target => "@timestamp"
      timezone => "Asia/Kolkata"
    }
  }

  mutate {
    remove_field => [
        "agent.ephemeral_id",
        "agent.id",
        "host.mac",
        "host.ip",
        "host.architecture",
        "host.containerized",
        "warning_message"
      ]
    }
}

output {
    elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "jpos-prod-logs1-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "changeme"
  }
}
